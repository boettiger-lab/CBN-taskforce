{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b4adc2a-bf0c-4ace-87be-dbaf90be0125",
   "metadata": {},
   "source": [
    "# Pre-processing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e6298c-d886-432a-a1b7-c3fee914c24f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "data_path = '../data/CBN-layers/'\n",
    "os.chdir(data_path)\n",
    "\n",
    "from cng.utils import ST_MakeValid, set_secrets, s3_client\n",
    "s3 = s3_client()\n",
    "\n",
    "import ibis\n",
    "from ibis import _\n",
    "con = ibis.duckdb.connect(extensions=[\"spatial\"])\n",
    "\n",
    "import geopandas as gpd\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8741e72a-5976-440b-9279-77f959c6ae24",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63dd33b8-6d3c-4852-9899-6ed5775d19c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(folder, file, base_folder = 'CBN-data'):\n",
    "    minio = 'https://minio.carlboettiger.info/'\n",
    "    bucket = 'public-ca30x30'\n",
    "    if base_folder is None:\n",
    "        path = os.path.join(bucket,folder,file)\n",
    "    else:\n",
    "        path = os.path.join(bucket,base_folder,folder,file)\n",
    "    url = minio+path\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743cbbfd-4da4-47eb-b0f6-b5f713687839",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13214bbe-3a74-4247-981f-5a6eb6c486f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CA Nature data \n",
    "ca_raw_parquet = \"https://data.source.coop/cboettig/ca30x30/ca_areas.parquet\"\n",
    "\n",
    "# Boundary of CA, used to computed 'non-conserved' areas\n",
    "ca_boundary_parquet = get_url('Preprocessing','ca_boundary.parquet',base_folder = None)\n",
    "\n",
    "# newly protected areas \n",
    "newly_protected = get_url('Progress_data_new_protection/Newly_counted_lands','newly_counted_lands_2024.parquet')\n",
    "\n",
    "# Ecoregions\n",
    "ecoregions = get_url('Ecoregion','ACE_ecoregions.parquet')\n",
    "\n",
    "# file to save non-conserved areas; costly operation so we save results \n",
    "ca_nonconserved_parquet_local = \"ca_nonconserved_simplified500m.parquet\" # local copy \n",
    "ca_nonconserved_parquet = get_url('Preprocessing',ca_nonconserved_parquet_local,base_folder = None)\n",
    "ca_nonconserved_eco_parquet_local = \"ca_nonconserved_simplified500m_ecoregions.parquet\" # local copy \n",
    "ca_nonconserved_eco_parquet = get_url('Preprocessing',ca_nonconserved_eco_parquet_local ,base_folder = None)\n",
    "\n",
    "# temp file only of CA Nature data + non-conserved areas  \n",
    "ca_base_parquet = \"ca-30x30-base.parquet\"\n",
    "ca_temp_parquet = \"ca-30x30-temp.parquet\"  \n",
    "\n",
    "# temp file used to compute metrics w/ data layers \n",
    "ca_temp_stats_parquet = \"ca-30x30-stats-temp.parquet\"  \n",
    "\n",
    "#vector data \n",
    "ACE_rarerank_statewide = get_url('ACE_biodiversity/ACE_rarerank_statewide','ACE_rarerank_statewide.parquet')\n",
    "ACE_rarerank_ecoregion = get_url('ACE_biodiversity/ACE_rarerank_ecoregion','ACE_rarerank_ecoregion.parquet')\n",
    "ACE_biorank_statewide = get_url('ACE_biodiversity/ACE_biorank_statewide','ACE_biorank_statewide.parquet')\n",
    "ACE_biorank_ecoregion = get_url('ACE_biodiversity/ACE_biorank_ecoregion','ACE_biorank_ecoregion.parquet')\n",
    "\n",
    "ACE_amph_richness = get_url('ACE_biodiversity/ACE_amphibian_richness','ACE_amphibian_richness.parquet')\n",
    "ACE_reptile_richness = get_url('ACE_biodiversity/ACE_reptile_richness','ACE_reptile_richness.parquet')\n",
    "ACE_bird_richness = get_url('ACE_biodiversity/ACE_bird_richness','ACE_bird_richness.parquet')\n",
    "ACE_mammal_richness = get_url('ACE_biodiversity/ACE_mammal_richness','ACE_mammal_richness.parquet')\n",
    "ACE_rare_amphibian_richness = get_url('ACE_biodiversity/ACE_rare_amphibian_richness','ACE_rare_amphibian_richness.parquet')\n",
    "ACE_rare_reptile_richness = get_url('ACE_biodiversity/ACE_rare_reptile_richness','ACE_rare_reptile_richness.parquet')\n",
    "ACE_rare_bird_richness = get_url('ACE_biodiversity/ACE_rare_bird_richness','ACE_rare_bird_richness.parquet')\n",
    "ACE_rare_mammal_richness = get_url('ACE_biodiversity/ACE_rare_mammal_richness','ACE_rare_mammal_richness.parquet')\n",
    "ACE_endemic_amphibian_richness = get_url('ACE_biodiversity/ACE_endemic_amphibian_richness','ACE_endemic_amphibian_richness.parquet')\n",
    "ACE_endemic_reptile_richness = get_url('ACE_biodiversity/ACE_endemic_reptile_richness','ACE_endemic_reptile_richness.parquet')\n",
    "ACE_endemic_bird_richness = get_url('ACE_biodiversity/ACE_endemic_bird_richness','ACE_endemic_bird_richness.parquet')\n",
    "ACE_endemic_mammal_richness = get_url('ACE_biodiversity/ACE_endemic_mammal_richness','ACE_endemic_mammal_richness.parquet')\n",
    "\n",
    "wetlands = get_url('Freshwater_resources/Wetlands','CA_wetlands.parquet')\n",
    "fire = get_url('Climate_risks/Historical_fire_perimeters','calfire_2023.parquet')\n",
    "farmland = get_url('NBS_agriculture/Lands_suitable_grazing','Farmland_2018.parquet')\n",
    "grazing = get_url('NBS_agriculture/Lands_suitable_grazing','Grazing_land_2018.parquet')\n",
    "DAC = get_url('Progress_data_new_protection/DAC','DAC_2022.parquet')\n",
    "low_income = get_url('Progress_data_new_protection/Low_income_communities','low_income_CalEnviroScreen4.parquet')\n",
    "\n",
    "# raster data\n",
    "climate_zones = get_url('Climate_zones', 'climate_zones_10_processed.tif')\n",
    "habitat = get_url('Habitat', 'CWHR13_2022_processed.tif')\n",
    "plant_richness = get_url('Biodiversity_unique/Plant_richness', 'species_D_processed.tif')\n",
    "endemic_plant_richness = get_url('Biodiversity_unique/Rarityweighted_endemic_plant_richness', 'endemicspecies_E_processed.tif')\n",
    "resilient_conn_network = get_url('Connectivity_resilience/Resilient_connected_network_allcategories', \n",
    "                                 'rcn_wIntactBioCat_caOnly_2020-10-27_processed.tif')\n",
    "\n",
    "# final files: conserved + non-conserved areas + data layers \n",
    "ca_parquet = \"ca-30x30-cbn.parquet\"\n",
    "ca_pmtiles = \"ca-30x30-cbn.pmtiles\" #excludes non-conserved geometries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907235f6-48a5-4c55-b779-3bb6839acf2b",
   "metadata": {},
   "source": [
    "# Step 1: Computing all \"non-conserved\" areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfcb35b-e6a9-4a89-af05-c65909191f2b",
   "metadata": {},
   "source": [
    "#### Computing difference: Non-conserved areas = CA Boundary - Conserved Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aedc147-6601-4ca7-9316-ddea5cab154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This chunk will take ~2 hours to run \n",
    "conn = ibis.duckdb.connect(\"tmp\", extensions=[\"spatial\"]) #save to disk\n",
    "\n",
    "# CA Boundary \n",
    "ca_all_tbl = (\n",
    "    conn.read_parquet(ca_boundary_parquet)\n",
    "    .rename(geom = \"geometry\")\n",
    "    .cast({\"geom\": \"geometry\"})\n",
    ")\n",
    "\n",
    "# CA-Nature data / protected areas \n",
    "tbl = (\n",
    "    conn.read_parquet(ca_raw_parquet)\n",
    "    .cast({\"SHAPE\": \"geometry\"})\n",
    "    .rename(geom = \"SHAPE\")\n",
    ")\n",
    "\n",
    "conn.create_table(\"t1\", ca_all_tbl, overwrite = True)\n",
    "conn.create_table(\"t2\", tbl.filter(_.Release_Year == 2024), overwrite = True)\n",
    "\n",
    "# simplified all geometries 500m so the kernel doesn't crash\n",
    "# computing difference\n",
    "conn.conn.execute('''\n",
    "CREATE TABLE not_in_pad AS\n",
    "WITH t2_simplified AS (\n",
    "    SELECT ST_Simplify(geom, 500) AS geom\n",
    "    FROM t2\n",
    "),\n",
    "t2_union AS (\n",
    "    SELECT ST_Union_Agg(geom) AS geom\n",
    "    FROM t2_simplified\n",
    ")\n",
    "SELECT \n",
    "    ST_Difference(t1.geom, t2_union.geom) AS geom\n",
    "FROM \n",
    "    t1, t2_union;\n",
    "''')\n",
    "\n",
    "\n",
    "# save to parquet file so we don't have to run this again\n",
    "nonconserved = conn.table(\"not_in_pad\")\n",
    "nonconserved.execute().to_parquet(ca_nonconserved_parquet_local)\n",
    "\n",
    "# upload to minio\n",
    "s3.fput_object(\"public-ca30x30\", 'Preprocessing/'+ca_nonconserved_parquet_local, ca_nonconserved_parquet_local) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5689850-80fa-4cc9-87e9-46074b8d9107",
   "metadata": {},
   "source": [
    "#### Compute ecoregion for non-conserved areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070bbdde-b141-4a63-8f8a-984dd01fd51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eco = con.read_parquet(ecoregions)\n",
    "non = con.read_parquet(ca_nonconserved_parquet)\n",
    "\n",
    "con.create_table(\"eco\", eco.select(\"ECOREGION_\",\"geom\"), overwrite = True)\n",
    "\n",
    "con.create_table(\"non\", non, overwrite = True)\n",
    "            \n",
    "#split up the non-conserved areas by ecoregions\n",
    "con.con.execute('''\n",
    "CREATE TABLE non_conserved_eco AS\n",
    "SELECT \n",
    "    non.*, \n",
    "    eco.ECOREGION_ AS ecoregion,\n",
    "    ST_Intersection(non.geom, eco.geom) AS geom  -- Split non into ecoregions\n",
    "FROM non\n",
    "JOIN eco \n",
    "ON ST_Intersects(non.geom, eco.geom)\n",
    "WHERE ST_GeometryType(ST_Intersection(non.geom, eco.geom)) IN ('POLYGON', 'MULTIPOLYGON');\n",
    "''')\n",
    "\n",
    "# save to parquet file so we don't have to run this again\n",
    "non_eco = (con.table(\"non_conserved_eco\")\n",
    "           .drop('geom')\n",
    "           .rename(geom = \"geom_1\")\n",
    "           .mutate(geom = ST_MakeValid(_.geom))\n",
    "           .mutate(id=ibis.row_number().over())\n",
    "          )\n",
    "\n",
    "non_conserved_eco = non_eco.execute()\n",
    "non_conserved_eco.to_parquet(ca_nonconserved_eco_parquet_local)\n",
    "\n",
    "# upload to minio\n",
    "s3.fput_object(\"public-ca30x30\", 'Preprocessing/' + ca_nonconserved_eco_parquet_local, \n",
    "               ca_nonconserved_eco_parquet_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce52b1e0-027e-4915-9e7b-e51e946560ed",
   "metadata": {},
   "source": [
    "#### Non-conserved areas need to match CA Nature schema when merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9666d1-7c2b-45af-9399-e4189bba34f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match CA Nature schema \n",
    "nonconserved_clean = (\n",
    "    con.read_parquet(ca_nonconserved_eco_parquet)\n",
    "    .cast({\"geom\": \"geometry\"})\n",
    "    .mutate(established = ibis.null(), gap_code = 0, name = ibis.literal(\"Non-Conserved Areas\"),\n",
    "            access_type = ibis.null(), manager = ibis.null(), manager_type = ibis.null(),\n",
    "            easement = ibis.null(), type = ibis.literal(\"Land\"),\n",
    "            status = ibis.literal(\"non-conserved\"),\n",
    "            acres = _.geom.area() / 4046.8564224 #convert sq meters to acres\n",
    "           )\n",
    "    .cast({\"established\": \"string\", \"gap_code\": \"int16\", \"status\": \"string\",\"name\": \"string\",\n",
    "          \"access_type\": \"string\", \"manager\": \"string\", \"manager_type\": \"string\",\n",
    "          \"ecoregion\": \"string\", \"easement\": \"string\", \"id\": \"int64\", \"type\": \"string\",\n",
    "          \"acres\":\"float32\"}) #match schema to CA Nature\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104254ef-f6e9-4f03-8797-de55091774d5",
   "metadata": {},
   "source": [
    "# Step 2: Isolate the \"newly protected\" polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d4f189-1563-4868-9f1f-64d67569df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # negative buffer to account for overlapping boundaries. \n",
    "# buffer = -30 #30m buffer \n",
    "\n",
    "# tbl = (\n",
    "#     con.read_parquet(ca_raw_parquet)\n",
    "#     .cast({\"SHAPE\": \"geometry\"})\n",
    "#     .rename(geom = \"SHAPE\")\n",
    "#     .filter(_.reGAP < 3) # only gap 1 and 2 count towards 30x30\n",
    "# )\n",
    "\n",
    "# # polygons with release_year 2024 are a superset of release_year 2023. \n",
    "# # use anti_join to isolate the objects that are in release_year 2024 but not release_year 2023 (aka newly established). \n",
    "# tbl_2023 = tbl.filter(_.Release_Year == 2023).mutate(geom=_.geom.buffer(buffer)) \n",
    "# tbl_2024 = tbl.filter(_.Release_Year == 2024)\n",
    "# intersects = tbl_2024.anti_join(tbl_2023, _.geom.intersects(tbl_2023.geom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07a4f0a-e717-4a11-bbce-4e96d7da7293",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = 160 #0.1mile buffer \n",
    "\n",
    "tbl_2024 = (\n",
    "    con.read_parquet(ca_raw_parquet)\n",
    "    .cast({\"SHAPE\": \"geometry\"})\n",
    "    .rename(geom = \"SHAPE\")\n",
    "    .filter(_.Release_Year == 2024)\n",
    "    .mutate(geom=_.geom.buffer(buffer)) \n",
    ")\n",
    "\n",
    "tbl_new = (\n",
    "    con.read_parquet(newly_protected)\n",
    ")\n",
    "\n",
    "intersects = tbl_new.anti_join(tbl_2024, _.geom.intersects(tbl_2024.geom))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f335433-ff89-4966-bf98-c11a0b233686",
   "metadata": {},
   "source": [
    "# Step 3: Join all protected lands + non-conserved areas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59c976b-3c36-40f9-a15b-cefcd155c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "new2024 = intersects.select(\"OBJECTID\").mutate(established = ibis.literal(\"2024\")) # saving IDs to join on\n",
    "\n",
    "ca_merged = (con\n",
    "      .read_parquet(ca_raw_parquet)\n",
    "      .cast({\"SHAPE\": \"geometry\"})\n",
    "      .mutate(area = _.SHAPE.area())\n",
    "      .filter(_.Release_Year == 2024) # having both 2023 and 2024 is redudant since 2024 is the superset.\n",
    "      .left_join(new2024, \"OBJECTID\") # newly established 2024 polygons \n",
    "      .mutate(established=_.established.fill_null(\"pre-2024\")) \n",
    "      .rename(name = \"cpad_PARK_NAME\", access_type = \"cpad_ACCESS_TYP\", manager = \"cpad_MNG_AGENCY\",\n",
    "              manager_type = \"cpad_MNG_AG_LEV\", id = \"OBJECTID\", type = \"TYPE\", \n",
    "              ecoregion = \"CA_Ecoregion_Name\", acres = \"Acres\", gap_code = \"reGAP\", geom = \"SHAPE\")\n",
    "      .cast({\"gap_code\": \"int16\"})\n",
    "      .cast({\"id\": \"int64\"})\n",
    "      .mutate(manager = _.manager.substitute({\"\": \"Unknown\"})) \n",
    "      .mutate(manager_type = _.manager_type.substitute({\"\": \"Unknown\"}))\n",
    "      .mutate(access_type = _.access_type.substitute({\"\": \"Unknown Access\"}))\n",
    "      .mutate(name = _.name.substitute({\"\": \"Unknown\"}))\n",
    "      .mutate(manager_type = _.manager_type.substitute({\"Home Owners Association\": \"HOA\"}))\n",
    "      .mutate(easement=_.Easement.cast(\"string\").substitute({\"0\": \"False\", \"1\": \"True\"}))\n",
    "      .mutate(status=_.gap_code.cast(\"string\")\n",
    "              .substitute({\"1\": \"30x30-conserved\", \"2\": \"30x30-conserved\", \"3\": \"other-conserved\", \n",
    "                           \"4\": \"unknown\"}))\n",
    "      .select(_.established, _.gap_code, _.status, _.name, _.access_type, _.manager, _.manager_type,\n",
    "              _.ecoregion, _.easement, _.acres, _.id, _.type, _.geom)\n",
    "      .union(nonconserved_clean)\n",
    "      .mutate(acres = _.acres.round(4))\n",
    "      .mutate(geom = ST_MakeValid(_.geom))\n",
    "      .drop_null(['geom'],how = \"any\")\n",
    "     )\n",
    "\n",
    "ca = ca_merged.execute()\n",
    "gdf.set_crs(\"epsg:3310\").to_parquet(ca_temp_parquet) # saving to temp file to compute zonal stats "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fcaef1-2cea-4330-9715-76fa94357921",
   "metadata": {},
   "source": [
    "#### Join with county data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6177e2-8ece-4eb9-acc2-5fb5c5beb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = con.read_parquet('../CA_counties.parquet')\n",
    "ca = con.read_parquet(ca_base_parquet)\n",
    "\n",
    "con.create_table(\"counties\", counties.select(\"COUNTY_NAM\",\"geom\"), overwrite = True)\n",
    "con.create_table(\"ca\", ca, overwrite = True)\n",
    "\n",
    "con.con.execute('''\n",
    "CREATE TABLE counties_data AS\n",
    "SELECT \n",
    "    ca.*, \n",
    "    counties.COUNTY_NAM AS county,\n",
    "    ST_Intersection(ca.geom, counties.geom) AS geom\n",
    "FROM ca\n",
    "JOIN counties \n",
    "  ON ST_Intersects(ca.geom, counties.geom)\n",
    "WHERE NOT ST_IsEmpty(ST_Intersection(ca.geom, counties.geom))\n",
    "  AND ST_GeometryType(ST_Intersection(ca.geom, counties.geom)) IN ('POLYGON', 'MULTIPOLYGON');\n",
    "''')\n",
    "\n",
    "county_data = (con.table(\"counties_data\")\n",
    "           .drop('geom')\n",
    "           .rename(geom = \"geom_1\")\n",
    "           .mutate(geom = ST_MakeValid(_.geom))\n",
    "           .mutate(acres = _.geom.area() / 4046.8564224) #convert sq meters to acres\n",
    "          )\n",
    "gdf = county_data.execute()\n",
    "\n",
    "import string\n",
    "duplicated = gdf[\"id\"].duplicated(keep=False)\n",
    "\n",
    "# modify the ids for areas that span multiple counties \n",
    "gdf[\"suffix\"] = \"\"\n",
    "gdf.loc[duplicated, \"suffix\"] = (\n",
    "    gdf[duplicated]\n",
    "    .groupby(\"id\")\n",
    "    .cumcount()\n",
    "    .map(lambda i: string.ascii_lowercase[i])\n",
    ")\n",
    "\n",
    "# if id = 11 has 2 rows, make each row 11a and 11b\n",
    "# if id = 11 only has 1 row, keep it 11. \n",
    "gdf[\"id\"] = gdf[\"id\"].astype(str) + gdf[\"suffix\"]\n",
    "gdf = gdf.drop(columns=\"suffix\")\n",
    "\n",
    "gdf.set_crs(\"epsg:3310\").to_parquet(ca_base_parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d64f2b-a65b-4ac1-9943-2d96f5c91e1d",
   "metadata": {},
   "source": [
    "# Step 4: Compute metrics w/ data layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e924fd-d927-4458-ba1f-670b4047d149",
   "metadata": {},
   "source": [
    "#### Raster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce1bc61-eabd-4a73-ba34-a1707bc14f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import rasterio\n",
    "from exactextract import exact_extract\n",
    "\n",
    "rasters = [climate_zones, habitat, plant_richness, endemic_plant_richness, resilient_conn_network]\n",
    "names = ['climate_zone','habitat_type','plant_richness','rarityweighted_endemic_plant_richness', 'resilient_connected_network']\n",
    "\n",
    "if 'gdf_stats' not in locals(): \n",
    "    gdf_stats = gpd.read_parquet(ca_base_parquet) # read in data if it's not already created \n",
    "    \n",
    "# need to make the following changes to our data for exact_extract() to work:\n",
    "gdf_stats = gdf_stats.rename(columns ={'id':'ca_id'}) #rename 'id' because it conflicts with a raster field. \n",
    "gdf_stats.to_parquet(ca_temp_parquet) #saving updated parquet to file to use for exact_extract()\n",
    "\n",
    "for file,name in zip(rasters,names):\n",
    "    print(name)\n",
    "    if name in ['climate_zone','habitat_type','resilient_connected_network']:\n",
    "        metric = \"majority\"\n",
    "    else: \n",
    "        metric = \"count\"\n",
    "    raster_stats = exact_extract(file, ca_temp_parquet, [metric], include_cols=[\"ca_id\"], output = 'pandas') # compute overlap \n",
    "    raster_stats = raster_stats[['ca_id',metric]]\n",
    "    raster_stats = raster_stats.rename(columns ={metric:name})\n",
    "    raster_stats[name] = raster_stats[name].round(3) #rounding stats \n",
    "     \n",
    "    # joining with gpd.join(), need to set an index \n",
    "    gdf_stats = gdf_stats.set_index(\"ca_id\").join(raster_stats.set_index(\"ca_id\")) \n",
    "\n",
    "    # exact_extract() won't work with index, so now that it's joined, we reset the index. \n",
    "    gdf_stats = gdf_stats.reset_index() \n",
    "    # gdf_stats.to_parquet(name+'_overlap.parquet')\n",
    "\n",
    "gdf_stats = gdf_stats.rename(columns ={'ca_id':'id'}) #reverting back to \"id\" col name, since we are finished with exact_extract() \n",
    "gdf_stats.to_file('raster_stats.geojson') # can't save to parquet for some reason \n",
    "# reproject to epsg:4326 since that's what pmtiles requires and we want to match that \n",
    "\n",
    "# Wall time: 8min 43s\n",
    "# gdf_stats = gpd.read_file('raster_stats.geojson')\n",
    "# gdf_stats.to_parquet('raster_stats.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e129b0cc-ee7d-4e58-a8d8-d6f2476bd62c",
   "metadata": {},
   "source": [
    "#### Function to compute overlap for vector data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeeb7ac-efa0-4a7b-9143-72d8ec911809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_vector_stats(base, data_layer):\n",
    "    t1 = con.read_parquet(base).select(_.id, _.geom)\n",
    "    t2 = con.read_parquet(data_layer).select(_.geom)\n",
    "\n",
    "    expr = (t1\n",
    "     .left_join(t2, t1.geom.intersects(t2.geom))\n",
    "     .group_by(t1.id, t1.geom)\n",
    "     .agg(overlap_fraction = (t1.geom.intersection(t2.geom).area() / t1.geom.area()) \n",
    "\n",
    "          .sum().coalesce(0).round(3) ) # overlap \n",
    "    )\n",
    "    ibis.to_sql(expr)\n",
    "    stats = expr.execute()\n",
    "    return stats[['id','overlap_fraction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a0f52-6d18-45b4-8585-af3f1190b000",
   "metadata": {},
   "source": [
    "#### Vector data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110da15-d2ac-4457-9241-f02f44dc436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## this takes ~26 hours\n",
    "names = ['ACE_rarerank_statewide', 'ACE_rarerank_ecoregion',\n",
    "         'ACE_biorank_statewide', 'ACE_biorank_ecoregion',\n",
    "         'ACE_amphibian_richness','ACE_reptile_richness',\n",
    "         'ACE_bird_richness','ACE_mammal_richness',\n",
    "         'ACE_rare_amphibian_richness','ACE_rare_reptile_richness',\n",
    "         'ACE_rare_bird_richness','ACE_rare_mammal_richness',\n",
    "         'ACE_endemic_amphibian_richness','ACE_endemic_reptile_richness',\n",
    "         'ACE_endemic_bird_richness','ACE_endemic_mammal_richness',\n",
    "         'wetlands','fire','farmland','grazing','DAC','low_income']\n",
    "\n",
    "vectors = [ACE_rarerank_statewide, ACE_rarerank_ecoregion,\n",
    "           ACE_biorank_statewide, ACE_biorank_ecoregion,\n",
    "           ACE_amph_richness, ACE_reptile_richness,\n",
    "           ACE_bird_richness, ACE_mammal_richness,\n",
    "           ACE_rare_amphibian_richness, ACE_rare_reptile_richness,\n",
    "           ACE_rare_bird_richness, ACE_rare_mammal_richness,\n",
    "           ACE_endemic_amphibian_richness,\n",
    "           ACE_endemic_reptile_richness,\n",
    "           ACE_endemic_bird_richness,\n",
    "           ACE_endemic_mammal_richness,\n",
    "           wetlands, fire,\n",
    "           farmland, grazing,\n",
    "           DAC, low_income]\n",
    "\n",
    "\n",
    "gdf_stats = gpd.read_parquet('raster_stats.parquet') \n",
    "\n",
    " # set the index to the col we are joining on for gpd.join()\n",
    "gdf_stats = gdf_stats.set_index('id')\n",
    "\n",
    "for file,name in zip(vectors,names):\n",
    "    print(name)\n",
    "    vector_stats = vector_vector_stats(ca_base_parquet, file) \n",
    "    vector_stats = vector_stats.rename(columns ={'overlap_fraction':name}) \n",
    "\n",
    "    # joining new zonal stats column with CA Nature data. \n",
    "    gdf_stats = gdf_stats.join(vector_stats.set_index('id'))\n",
    "    gdf_stats.to_parquet(name+'.parquet') #save CA Nature + zonal stats \n",
    "\n",
    "gdf_stats = gdf_stats.reset_index()\n",
    "gdf_stats.to_parquet('vector_raster_stats.parquet') #save CA Nature + zonal stats \n",
    "gdf_stats\n",
    "\n",
    "# gdf_stats = gdf_stats.to_crs(\"epsg:4326\")\n",
    "# gdf_stats.to_parquet(ca_temp_parquet) # save results \n",
    "# gdf_stats.to_parquet(ca_parquet) # save results \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec619f4e-1338-492a-a334-a7796f4f55a1",
   "metadata": {},
   "source": [
    "# Step 5: Upload file + Generate PMTiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f47b26-cd18-4e8c-a19b-9d1f19b10873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cng.utils import hf_upload, s3_cp,set_secrets, to_pmtiles\n",
    "\n",
    "# upload parquet to minio and HF\n",
    "hf_upload('ca-30x30-cbn.parquet', ca_parquet)\n",
    "s3_cp(ca_parquet, \"s3://public-ca30x30/ca-30x30-cbn.parquet\", \"minio\")\n",
    "\n",
    "#to use PMTiles, need to convert to geojson\n",
    "ca_geojson = (con\n",
    "            .read_parquet(ca_parquet)\n",
    "            # .filter(_.status != 'non-conserved') #omitting the non-conserved to only for pmtiles  \n",
    "            )\n",
    "\n",
    "#can't go directly from parquet -> pmtiles, need to go parquet -> geojson -> pmtiles \n",
    "ca_geojson.execute().to_file('ca-30x30-cbn.geojson') \n",
    "pmtiles = to_pmtiles(path+ 'ca-30x30-cbn.geojson', ca_pmtiles, options = ['--extend-zooms-if-still-dropping'])\n",
    "\n",
    "# upload pmtiles  to minio and HF\n",
    "hf_upload('ca-30x30-cbn.pmtiles', ca_pmtiles)\n",
    "s3_cp(ca_pmtiles, \"s3://public-ca30x30/ca-30x30-cbn.pmtiles\", \"minio\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
