{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b4adc2a-bf0c-4ace-87be-dbaf90be0125",
   "metadata": {},
   "source": [
    "# Pre-processing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e6298c-d886-432a-a1b7-c3fee914c24f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ibis\n",
    "from ibis import _\n",
    "import geopandas as gpd\n",
    "import duckdb\n",
    "from cng.utils import ST_MakeValid\n",
    "\n",
    "conn = ibis.duckdb.connect(extensions=[\"spatial\"])\n",
    "ca_parquet = \"https://data.source.coop/cboettig/ca30x30/ca_areas.parquet\"\n",
    "# or use local copy:\n",
    "# ca_parquet = \"../data/ca_areas.parquet\" # CA Nature Data \n",
    "\n",
    "path = '../data/ca-layers/'\n",
    "\n",
    "# CA Nature Data \n",
    "ca_boundary = \"../data/ca_shape\"\n",
    "ca_boundary_parquet = path + \"ca_boundary.parquet\"\n",
    "ca_nonconserved_parquet = path + \"ca_notPAD_500m_simplify.parquet\"\n",
    "ca_all_parquet = path + \"ca-all.parquet\"\n",
    "ca_all_stats =  path + \"ca-all-stats.parquet\"\n",
    "ca_final_parquet = \"ca_30x30_stats.parquet\"\n",
    "#vector data \n",
    "svi = path + 'SVI2022_US_tract' #4326\n",
    "fire = path + 'calfire-2023'#4326\n",
    "rxburn = path + 'calfire-rxburn-2023'#4326\n",
    "\n",
    "#raster data \n",
    "irrecoverable_c = path + 'ca_irrecoverable_c_2018_cog' # EPSG:3857\n",
    "manageable_c = path + 'ca_manageable_c_2018_cog'# EPSG:3857\n",
    "richness = path + 'SpeciesRichness_All' # EPSG:3857\n",
    "rsr = path + 'RSR_All'# EPSG:3857\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907235f6-48a5-4c55-b779-3bb6839acf2b",
   "metadata": {},
   "source": [
    "# Step 1: Computing all \"non-conserved\" areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c1cbf5-bc6e-4238-ab87-c467067235c0",
   "metadata": {},
   "source": [
    "#### Convert CA Boundary file to parquet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38091012-586e-4091-8f0d-a0aa868a04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a shape file of CA boundary and converting to parquet file \n",
    "ca_all = gpd.read_file(ca_boundary).to_crs(epsg = 3310)\n",
    "ca_all.to_parquet(ca_boundary_parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfcb35b-e6a9-4a89-af05-c65909191f2b",
   "metadata": {},
   "source": [
    "#### Computing difference: CA Boundary - Conserved Areas = Non-conserved areas\n",
    "(This chunk will take ~2 hours to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aedc147-6601-4ca7-9316-ddea5cab154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing difference: CA Boundary - Conserved Areas = Non-conserved areas\n",
    "# This chunk will take ~2 hours to run \n",
    "con = ibis.duckdb.connect(\"tmp\", extensions=[\"spatial\"]) #save to disk\n",
    "\n",
    "# CA Boundary \n",
    "ca_all_tbl = (\n",
    "    con.read_parquet(ca_boundary_parquet)\n",
    "    .rename(geom = \"geometry\")\n",
    "    .cast({\"geom\": \"geometry\"})\n",
    ")\n",
    "\n",
    "\n",
    "# CA-Nature data / protected areas \n",
    "tbl = (\n",
    "    con.read_parquet(ca_parquet)\n",
    "    .cast({\"SHAPE\": \"geometry\"})\n",
    "    .rename(geom = \"SHAPE\", gid = \"OBJECTID\")\n",
    ")\n",
    "\n",
    "con.create_table(\"t1\", ca_all_tbl, overwrite = True)\n",
    "con.create_table(\"t2\", tbl.filter(_.Release_Year == 2024), overwrite = True)\n",
    "\n",
    "# simplified all geometries 500m so the kernel doesn't crash\n",
    "# computing difference\n",
    "con.con.execute('''\n",
    "CREATE TABLE not_in_pad AS\n",
    "WITH t2_simplified AS (\n",
    "    SELECT ST_Simplify(geom, 500) AS geom\n",
    "    FROM t2\n",
    "),\n",
    "t2_union AS (\n",
    "    SELECT ST_Union_Agg(geom) AS geom\n",
    "    FROM t2_simplified\n",
    ")\n",
    "SELECT \n",
    "    ST_Difference(t1.geom, t2_union.geom) AS geom\n",
    "FROM \n",
    "    t1, t2_union;\n",
    "''')\n",
    "\n",
    "\n",
    "# save to parquet file \n",
    "ca = con.table(\"not_in_pad\")\n",
    "ca.execute().to_parquet(ca_nonconserved_parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce52b1e0-027e-4915-9e7b-e51e946560ed",
   "metadata": {},
   "source": [
    "#### Non-conserved areas need to match CA Nature schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9666d1-7c2b-45af-9399-e4189bba34f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match CA Nature schema \n",
    "non_conserved = (\n",
    "    conn.read_parquet(ca_nonconserved_parquet)\n",
    "    .cast({\"geom\": \"geometry\"})\n",
    "    .mutate(established = ibis.null(), gap_code = 0, name = ibis.literal(\"Non-Conserved Areas\"),\n",
    "            access_type = ibis.null(), manager = ibis.null(), manager_type = ibis.null(),\n",
    "            ecoregion = ibis.null(), easement = ibis.null(), id = 0, type = ibis.literal(\"Land\"),\n",
    "            status = ibis.literal(\"non-conserved\"),\n",
    "            acres = _.geom.area() / 4046.8564224 #convert sq meters to acres\n",
    "           )\n",
    "    .cast({\"established\": \"string\", \"gap_code\": \"int16\", \"status\": \"string\",\"name\": \"string\",\n",
    "          \"access_type\": \"string\", \"manager\": \"string\", \"manager_type\": \"string\",\n",
    "          \"ecoregion\": \"string\", \"easement\": \"string\", \"id\": \"int64\", \"type\": \"string\",\n",
    "          \"acres\":\"float32\"}) #match schema to CA Nature\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104254ef-f6e9-4f03-8797-de55091774d5",
   "metadata": {},
   "source": [
    "# Step 2: Isolate pre-2024 from 2024 polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d4f189-1563-4868-9f1f-64d67569df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative buffer to account for overlapping boundaries. \n",
    "buffer = -30 #30m buffer \n",
    "\n",
    "tbl = (\n",
    "    conn.read_parquet(ca_parquet)\n",
    "    .cast({\"SHAPE\": \"geometry\"})\n",
    "    .rename(geom = \"SHAPE\")\n",
    "    .filter(_.reGAP < 3) # only gap 1 and 2 count towards 30x30\n",
    ")\n",
    "\n",
    "# polygons with release_year 2024 are a superset of release_year 2023. \n",
    "# use anti_join to isolate the objects that are in release_year 2024 but not release_year 2023 (aka newly established). \n",
    "tbl_2023 = tbl.filter(_.Release_Year == 2023).mutate(geom=_.geom.buffer(buffer)) \n",
    "tbl_2024 = tbl.filter(_.Release_Year == 2024)\n",
    "intersects = tbl_2024.anti_join(tbl_2023, _.geom.intersects(tbl_2023.geom))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f335433-ff89-4966-bf98-c11a0b233686",
   "metadata": {},
   "source": [
    "# Step 3: Join all protected land data into single parquet file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59c976b-3c36-40f9-a15b-cefcd155c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new2024 = intersects.select(\"OBJECTID\").mutate(established = ibis.literal(\"2024\")) # saving IDs to join on\n",
    "\n",
    "ca = (conn\n",
    "      .read_parquet(ca_parquet)\n",
    "      .cast({\"SHAPE\": \"geometry\"})\n",
    "      .mutate(area = _.SHAPE.area())\n",
    "      .filter(_.Release_Year == 2024) # having both 2023 and 2024 is redudant since 2024 is the superset.\n",
    "      .left_join(new2024, \"OBJECTID\") # newly established 2024 polygons \n",
    "      .mutate(established=_.established.fill_null(\"pre-2024\")) \n",
    "      .rename(name = \"cpad_PARK_NAME\", access_type = \"cpad_ACCESS_TYP\", manager = \"cpad_MNG_AGENCY\",\n",
    "              manager_type = \"cpad_MNG_AG_LEV\", id = \"OBJECTID\", type = \"TYPE\", \n",
    "              ecoregion = \"CA_Ecoregion_Name\", acres = \"Acres\", gap_code = \"reGAP\", geom = \"SHAPE\")\n",
    "      .cast({\"gap_code\": \"int16\"})\n",
    "      .cast({\"id\": \"int64\"})\n",
    "      .mutate(manager = _.manager.substitute({\"\": \"Unknown\"})) \n",
    "      .mutate(manager_type = _.manager_type.substitute({\"\": \"Unknown\"}))\n",
    "      .mutate(access_type = _.access_type.substitute({\"\": \"Unknown Access\"}))\n",
    "      .mutate(name = _.name.substitute({\"\": \"Unknown\"}))\n",
    "      .mutate(manager_type = _.manager_type.substitute({\"Home Owners Association\": \"HOA\"}))\n",
    "      .mutate(easement=_.Easement.cast(\"string\").substitute({\"0\": \"False\", \"1\": \"True\"}))\n",
    "      .mutate(status=_.gap_code.cast(\"string\")\n",
    "              .substitute({\"1\": \"30x30-conserved\", \"2\": \"30x30-conserved\", \"3\": \"other-conserved\", \n",
    "                           \"4\": \"other-conserved\"}))\n",
    "      .select(_.established, _.gap_code, _.status, _.name, _.access_type, _.manager, _.manager_type,\n",
    "              _.ecoregion, _.easement, _.acres, _.id, _.type, _.geom)\n",
    "      .union(non_conserved)\n",
    "      .mutate(acres = _.acres.round(4))\n",
    "      .mutate(geom = ST_MakeValid(_.geom))\n",
    "      .drop_null(['geom'],how = \"any\")\n",
    "     )\n",
    "\n",
    "\n",
    "ca2024 = ca.execute()\n",
    "ca2024 = ca2024.set_crs(\"epsg:3310\")\n",
    "ca2024.to_parquet(ca_all_parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d64f2b-a65b-4ac1-9943-2d96f5c91e1d",
   "metadata": {},
   "source": [
    "# Step 4: Compute zonal stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e129b0cc-ee7d-4e58-a8d8-d6f2476bd62c",
   "metadata": {},
   "source": [
    "#### Functions: Reproject and compute overlap for vector data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeeb7ac-efa0-4a7b-9143-72d8ec911809",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = ibis.duckdb.connect(\"tmp2\", extensions=[\"spatial\"])\n",
    "\n",
    "def reproject_vectors(file, gdf_temp): # change data layer projections to match CA Nature data \n",
    "    gdf_temp = gdf_temp.rename_geometry('geom')\n",
    "    gdf_temp[\"geom\"] = gdf_temp[\"geom\"].make_valid()\n",
    "    gdf_temp = gdf_temp.to_crs(\"EPSG:3310\")\n",
    "    gdf_temp.to_parquet(file + '-epsg3310.parquet')\n",
    "    return\n",
    "\n",
    "def vector_vector_stats(base, data_layer):\n",
    "    t1 = con.read_parquet(base).select(_.id, _.geom)\n",
    "    t2 = con.read_parquet(data_layer).select(_.geom)\n",
    "    expr = (t1\n",
    "     .left_join(t2, t1.geom.intersects(t2.geom))\n",
    "     .group_by(t1.id, t1.geom)\n",
    "     .agg(overlap_fraction = (t1.geom.intersection(t2.geom).area() / t1.geom.area()).sum().coalesce(0).round(3) )\n",
    "    )\n",
    "    ibis.to_sql(expr)\n",
    "    gdf = expr.execute()\n",
    "    return gdf[['id','overlap_fraction']]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a0f52-6d18-45b4-8585-af3f1190b000",
   "metadata": {},
   "source": [
    "#### Compute zonal stats with vector data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110da15-d2ac-4457-9241-f02f44dc436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vectors = [svi,fire,rxburn]\n",
    "names = ['svi','fire','rxburn']\n",
    "\n",
    "gdf = gpd.read_parquet(ca_all_parquet) # CA Nature data \n",
    "gdf = gdf.set_index('id') # set the index to the col we are joining on for gpd.join()\n",
    "\n",
    "# clean data + reproject + zonal stats \n",
    "for file,name in zip(vectors,names):\n",
    "    gdf_temp = gpd.read_parquet(file + '.parquet') #load in vector data layer \n",
    "\n",
    "    # filter: we only want 10 year range for fire\n",
    "    if name in ['fire','rxburn']:\n",
    "        gdf_temp = gdf_temp[gdf_temp['YEAR_']>=2013] \n",
    "\n",
    "     # filter: only want CA data, not nationwide. \n",
    "    if name == 'svi': \n",
    "        gdf_temp = gdf_temp[gdf_temp['STATE']==\"California\"]\n",
    "        \n",
    "    reproject_vectors(file, gdf_temp) # change projection to match CA Nature data \n",
    "    gdf_zonal = vector_vector_stats(ca_all_parquet, file + '-epsg3310.parquet') #compute zonal stats \n",
    "    gdf_zonal = gdf_zonal.rename(columns ={'overlap_fraction':name}) \n",
    "    gdf = gdf.join(gdf_zonal.set_index('id')) # joining new zonal stats column with CA Nature data. \n",
    "\n",
    "gdf.to_parquet(ca_all_stats) #save CA Nature + zonal stats "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fccaf3-50a8-4324-82fa-34838987334b",
   "metadata": {},
   "source": [
    "#### Function: Reproject raster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aade11d9-87b9-403d-bad1-3069663807a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def raster_reprojection(input_file, output_file, epsg=\"EPSG:3310\"):\n",
    "    cmd = [\n",
    "        \"gdalwarp\",\n",
    "        \"-t_srs\", epsg,\n",
    "        input_file,\n",
    "        output_file\n",
    "    ]\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True)\n",
    "        print(f\"Reprojection successful! Output saved to: {output_file}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error occurred during reprojection: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e924fd-d927-4458-ba1f-670b4047d149",
   "metadata": {},
   "source": [
    "#### Compute zonal stats with raster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce1bc61-eabd-4a73-ba34-a1707bc14f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import rasterio\n",
    "from exactextract import exact_extract\n",
    "\n",
    "rasters = [irrecoverable_c, manageable_c, richness, rsr]\n",
    "names = ['irrecoverable_carbon','manageable_carbon','richness','rsr']\n",
    "\n",
    "gdf = gpd.read_parquet(ca_all_stats) # zonal stats data from vector data layers step \n",
    "\n",
    "# exact_extract() is a bit finnicky so we need to make the following changes to our data for it to work:\n",
    "gdf.index.names = ['ca_id'] # rename \"id\" since it confuses the name with a field in the raster data\n",
    "gdf = gdf.reset_index() # can't have an index \n",
    "gdf.to_parquet(ca_all_stats) #saving changes \n",
    "\n",
    "for file,name in zip(rasters,names):\n",
    "    raster_reprojection(file+'.tif', file+'_epsg3310.tif') #reproject rasters to match CA Nature\n",
    "    temp = exact_extract(file+'_epsg3310.tif', ca_all_stats, [\"mean\"], include_cols=[\"ca_id\"], output = 'pandas') #zonal stats \n",
    "    \n",
    "    #the column we want is 'band_1_mean'; these rasters have multiple bands. \n",
    "    if name in ['irrecoverable_carbon','manageable_carbon']:\n",
    "        temp = temp[['ca_id','band_1_mean']] \n",
    "        temp = temp.rename(columns ={'band_1_mean':name}) \n",
    "\n",
    "    #these rasters have only 1 band, so zonal stats column is 'mean'\n",
    "    elif name in ['richness','rsr']:\n",
    "        temp = temp[['ca_id','mean']] \n",
    "        temp = temp.rename(columns ={'mean':name})\n",
    "\n",
    "    temp[name] = temp[name].round(3) #rounding stats \n",
    "     \n",
    "    # joining with gpd.join(), need to set an index \n",
    "    gdf = gdf.set_index(\"ca_id\").join(temp.set_index(\"ca_id\")) \n",
    "\n",
    "    # exact_extract() won't work with index, so now that it's joined, we reset the index. \n",
    "    gdf = gdf.reset_index() \n",
    "\n",
    "gdf = gdf.rename(columns ={'ca_id':'id'}) #reverting back to \"id\" col name, since we are finished with exact_extract() \n",
    "gdf.to_parquet(ca_all_stats) # save results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec619f4e-1338-492a-a334-a7796f4f55a1",
   "metadata": {},
   "source": [
    "# Step 5: Upload file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f47b26-cd18-4e8c-a19b-9d1f19b10873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cng.utils import set_secrets, hf_upload, s3_cp \n",
    "conn = ibis.duckdb.connect(extensions=[\"spatial\"])\n",
    "\n",
    "set_secrets(conn)\n",
    "\n",
    "#to use PMTiles, I need to convert to 4326\n",
    "ca_all = (conn\n",
    "          .read_parquet(ca_all_stats)\n",
    "          .mutate(geom = _.geom.convert(\"epsg:3310\",\"epsg:4326\"))\n",
    "         )\n",
    "\n",
    "ca_all = ca_all.execute()\n",
    "ca_all = ca_all.set_crs(\"epsg:4326\")\n",
    "ca_all.to_parquet(path + ca_final_parquet)\n",
    "\n",
    "# upload to minio and HF\n",
    "hf_upload(ca_final_parquet, path+ca_final_parquet)\n",
    "s3_cp(path+ca_final_parquet, \"s3://public-ca30x30/\"+ca_final_parquet, \"minio\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856646af-4abb-41bb-99a6-2c10f6409cad",
   "metadata": {},
   "source": [
    "### PMTiles for app display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c52136c-df9a-4998-a9e9-055d80ee4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cng.utils import to_geojson, to_pmtiles\n",
    "to_geojson(path+ca_final_parquet, path+ 'ca_30x30_stats.geojson')\n",
    "\n",
    "pmtiles = to_pmtiles(path+ 'ca_30x30_stats.geojson',path+ 'ca_30x30_stats.pmtiles')\n",
    "hf_upload(\"ca_30x30_stats.pmtiles\",path+ 'ca_30x30_stats.pmtiles')\n",
    "s3_cp(path+ 'ca_30x30_stats.pmtiles', \"s3://public-ca30x30/ca_30x30_stats.pmtiles\", \"minio\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
